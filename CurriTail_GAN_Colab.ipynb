{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed39a85e",
   "metadata": {},
   "source": [
    "## üîß 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e03a566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è WARNING: GPU not available! Training will be very slow.\")\n",
    "    print(\"Go to Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df1a95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive for persistent storage\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create project directory in Drive\n",
    "import os\n",
    "project_dir = '/content/drive/MyDrive/CurriTail_GAN'\n",
    "os.makedirs(project_dir, exist_ok=True)\n",
    "print(f\"Project directory: {project_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16efb29",
   "metadata": {},
   "source": [
    "## üì¶ 2. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6a25b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install required packages (silent mode)\n",
    "!pip install yfinance statsmodels seaborn tqdm scipy scikit-learn matplotlib pandas numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c54769",
   "metadata": {},
   "source": [
    "## üìÇ 3. Upload Code Files\n",
    "\n",
    "**Option A: Upload from local machine** (recommended for first run)\n",
    "- Run the cell below and upload all `.py` files from your local project\n",
    "\n",
    "**Option B: Clone from GitHub** (if you have a repo)\n",
    "- Uncomment and modify the git clone command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d319da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: Upload files manually\n",
    "from google.colab import files\n",
    "\n",
    "print(\"üì§ Upload ALL .py files from your project:\")\n",
    "print(\"   - config.py\")\n",
    "print(\"   - utils.py\")\n",
    "print(\"   - models.py\")\n",
    "print(\"   - metrics.py\")\n",
    "print(\"   - baselines.py\")\n",
    "print(\"   - statistical_tests.py\")\n",
    "print(\"   - portfolio.py\")\n",
    "print(\"   - plotting.py\")\n",
    "print(\"   - main_experiment.py\")\n",
    "print(\"   - (optional) test_suite.py, failure_analysis.py\")\n",
    "print(\"\\nSelect multiple files at once!\")\n",
    "\n",
    "uploaded = files.upload()\n",
    "print(f\"\\n‚úÖ Uploaded {len(uploaded)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808ed3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option B: Clone from GitHub (uncomment if using)\n",
    "# !git clone https://github.com/YOUR_USERNAME/curtail_gan.git\n",
    "# %cd curtail_gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c48b226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify all required files are present\n",
    "import os\n",
    "\n",
    "required_files = [\n",
    "    'config.py', 'utils.py', 'models.py', 'metrics.py', \n",
    "    'baselines.py', 'statistical_tests.py', 'portfolio.py',\n",
    "    'plotting.py', 'main_experiment.py'\n",
    "]\n",
    "\n",
    "missing = [f for f in required_files if not os.path.exists(f)]\n",
    "\n",
    "if missing:\n",
    "    print(\"‚ùå Missing files:\")\n",
    "    for f in missing:\n",
    "        print(f\"   - {f}\")\n",
    "else:\n",
    "    print(\"‚úÖ All required files present!\")\n",
    "    print(\"\\nFiles in current directory:\")\n",
    "    !ls -lh *.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb2649d",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 4. Configure Experiment\n",
    "\n",
    "Choose your configuration:\n",
    "- **Quick Test** (2-3 hours): 5 seeds, 100 epochs, 1 dataset\n",
    "- **Medium Run** (8-10 hours): 10 seeds, 200 epochs, 2 datasets  \n",
    "- **Full Publication** (16-20 hours): 30 seeds, 400 epochs, 3 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045b2625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CONFIGURATION SELECTOR\n",
    "# ============================================\n",
    "\n",
    "# Choose one: 'quick', 'medium', 'full'\n",
    "RUN_MODE = 'quick'  # ‚Üê CHANGE THIS\n",
    "\n",
    "# Configuration parameters\n",
    "configs = {\n",
    "    'quick': {\n",
    "        'seeds': list(range(42, 47)),  # 5 seeds\n",
    "        'epochs': 100,\n",
    "        'datasets': ['Synthetic'],\n",
    "        'batch_size': 256,\n",
    "        'description': 'Quick test (2-3 hours)'\n",
    "    },\n",
    "    'medium': {\n",
    "        'seeds': list(range(42, 52)),  # 10 seeds\n",
    "        'epochs': 200,\n",
    "        'datasets': ['Synthetic', 'SPX'],\n",
    "        'batch_size': 256,\n",
    "        'description': 'Medium run (8-10 hours)'\n",
    "    },\n",
    "    'full': {\n",
    "        'seeds': list(range(42, 52)),  # 10 seeds\n",
    "        'epochs': 200,\n",
    "        'datasets': ['Synthetic', 'SPX', 'BTC'],\n",
    "        'batch_size': 256,\n",
    "        'description': 'Full publication (16-20 hours)'\n",
    "    }\n",
    "}\n",
    "\n",
    "cfg = configs[RUN_MODE]\n",
    "\n",
    "print(f\"üìä Selected Configuration: {cfg['description']}\")\n",
    "print(f\"   Seeds: {len(cfg['seeds'])} ({cfg['seeds'][0]} to {cfg['seeds'][-1]})\")\n",
    "print(f\"   Epochs: {cfg['epochs']}\")\n",
    "print(f\"   Datasets: {cfg['datasets']}\")\n",
    "print(f\"   Batch size: {cfg['batch_size']}\")\n",
    "print(f\"\\n‚è±Ô∏è Estimated runtime: {cfg['description'].split('(')[1].strip(')')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605fabeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify config.py with selected parameters\n",
    "import re\n",
    "\n",
    "# Read config.py\n",
    "with open('config.py', 'r') as f:\n",
    "    config_content = f.read()\n",
    "\n",
    "# Replace parameters in __post_init__\n",
    "replacements = [\n",
    "    (r'self\\.seeds = list\\(range\\(\\d+, \\d+\\)\\)', \n",
    "     f'self.seeds = {cfg[\"seeds\"]}'),\n",
    "    (r'epochs: int = \\d+', \n",
    "     f'epochs: int = {cfg[\"epochs\"]}'),\n",
    "    (r'self\\.datasets = \\[.*?\\]', \n",
    "     f'self.datasets = {cfg[\"datasets\"]}'),\n",
    "    (r'batch_size: int = \\d+',\n",
    "     f'batch_size: int = {cfg[\"batch_size\"]}')\n",
    "]\n",
    "\n",
    "for pattern, replacement in replacements:\n",
    "    config_content = re.sub(pattern, replacement, config_content)\n",
    "\n",
    "# Save modified config\n",
    "with open('config.py', 'w') as f:\n",
    "    f.write(config_content)\n",
    "\n",
    "print(\"‚úÖ Configuration updated!\")\n",
    "\n",
    "# Verify changes\n",
    "from config import CONFIG\n",
    "print(f\"\\nVerification:\")\n",
    "print(f\"  Seeds: {CONFIG.seeds[:3]}...{CONFIG.seeds[-1]} ({len(CONFIG.seeds)} total)\")\n",
    "print(f\"  Epochs: {CONFIG.epochs}\")\n",
    "print(f\"  Datasets: {CONFIG.datasets}\")\n",
    "print(f\"  Batch size: {CONFIG.batch_size}\")\n",
    "print(f\"  Device: {CONFIG.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162cb010",
   "metadata": {},
   "source": [
    "## üöÄ 5. Run Experiments\n",
    "\n",
    "**‚ö†Ô∏è Important Notes:**\n",
    "- Colab may disconnect after 12 hours of inactivity\n",
    "- For long runs, keep browser tab active or use Colab Pro\n",
    "- Results are saved incrementally to Google Drive\n",
    "- Progress bars show real-time status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26475482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run main experiment\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"üöÄ Starting CurriTail-GAN Experiments\")\n",
    "print(f\"üìÖ Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Redirect outputs to Google Drive\n",
    "import os\n",
    "os.makedirs(f\"{project_dir}/outputs\", exist_ok=True)\n",
    "os.makedirs(f\"{project_dir}/figures\", exist_ok=True)\n",
    "os.makedirs(f\"{project_dir}/saved_models\", exist_ok=True)\n",
    "\n",
    "# Run main experiment\n",
    "%run main_experiment.py\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(f\"‚úÖ Experiments Complete!\")\n",
    "print(f\"üìÖ End time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25c04f7",
   "metadata": {},
   "source": [
    "## üìä 6. View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3df136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary statistics\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Find latest results file\n",
    "result_files = sorted(glob.glob('outputs/summary_*.csv'))\n",
    "if result_files:\n",
    "    latest_summary = result_files[-1]\n",
    "    print(f\"üìÑ Loading: {latest_summary}\\n\")\n",
    "    \n",
    "    df_summary = pd.read_csv(latest_summary, index_col=[0, 1])\n",
    "    print(\"=\" * 80)\n",
    "    print(\"SUMMARY RESULTS (Mean ¬± Std across seeds)\")\n",
    "    print(\"=\" * 80)\n",
    "    print(df_summary)\n",
    "    \n",
    "    # Highlight best performers\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìà BEST PERFORMERS (by Tail KL Divergence - lower is better)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    all_results = pd.read_csv(result_files[-1].replace('summary', 'results_all_seeds'))\n",
    "    best_by_dataset = all_results.groupby('dataset')['tail_kl'].mean().groupby('model').mean()\n",
    "    print(best_by_dataset.sort_values())\n",
    "else:\n",
    "    print(\"‚ùå No results found yet. Run experiments first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d31b0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display generated figures\n",
    "from IPython.display import Image, display\n",
    "import glob\n",
    "\n",
    "figure_files = sorted(glob.glob('figures/*.png'))\n",
    "\n",
    "if figure_files:\n",
    "    print(f\"üìä Generated {len(figure_files)} figures:\\n\")\n",
    "    \n",
    "    for fig_path in figure_files:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"üìà {os.path.basename(fig_path)}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        display(Image(filename=fig_path, width=800))\n",
    "else:\n",
    "    print(\"‚ùå No figures found yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc9b2f7",
   "metadata": {},
   "source": [
    "## üìä 6b. Analyze Saved Models (Skip Retraining)\n",
    "\n",
    "If you already have trained models saved as `.pth` files, you can skip retraining and just run statistical analysis on the saved checkpoints. This is **much faster** (~2-3 minutes vs hours of training)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258ea931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the analyze_saved_models.py script\n",
    "from google.colab import files\n",
    "\n",
    "print(\"üì§ Upload analyze_saved_models.py:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "if 'analyze_saved_models.py' in uploaded:\n",
    "    print(\"‚úÖ analyze_saved_models.py uploaded successfully!\")\n",
    "else:\n",
    "    print(\"‚ùå Please upload analyze_saved_models.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64798090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run analysis on saved model checkpoints\n",
    "from analyze_saved_models import main\n",
    "\n",
    "print(\"üîç Analyzing saved model checkpoints...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Analyze models from Google Drive\n",
    "results, df_all, df_summary = main(\n",
    "    models_dir=f\"{project_dir}/saved_models\",  # Where your .pth files are\n",
    "    datasets=['SPX'],  # Or ['Synthetic', 'SPX', 'BTC']\n",
    "    generate_plots=True\n",
    ")\n",
    "\n",
    "if results:\n",
    "    print(\"\\n‚úÖ Analysis complete!\")\n",
    "    print(f\"\\nResults saved to: {project_dir}/outputs/\")\n",
    "    print(f\"Figures saved to: {project_dir}/figures/\")\n",
    "else:\n",
    "    print(\"\\n‚ùå No models found. Make sure .pth files are in:\")\n",
    "    print(f\"   {project_dir}/saved_models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7fee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the statistical comparison results\n",
    "if results and 'SPX' in results:\n",
    "    print(\"=\"*80)\n",
    "    print(\"üìä STATISTICAL COMPARISONS vs CurriTail\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if results['SPX']['statistical_comparisons'] is not None:\n",
    "        print(results['SPX']['statistical_comparisons'])\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìà VALIDATION AGAINST PAPER\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if results['SPX']['validation'] is not None:\n",
    "        print(results['SPX']['validation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6ca5a7",
   "metadata": {},
   "source": [
    "## üíæ 7. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c042f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy all outputs to Google Drive for persistence\n",
    "!cp -r outputs/ \"{project_dir}/\"\n",
    "!cp -r figures/ \"{project_dir}/\"\n",
    "!cp -r saved_models/ \"{project_dir}/\"\n",
    "!cp -r data_cache/ \"{project_dir}/\" 2>/dev/null || true\n",
    "\n",
    "print(f\"‚úÖ All results saved to Google Drive:\")\n",
    "print(f\"   {project_dir}/outputs/\")\n",
    "print(f\"   {project_dir}/figures/\")\n",
    "print(f\"   {project_dir}/saved_models/\")\n",
    "print(\"\\nüí° Access files from Google Drive even after Colab disconnects!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff41e093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create downloadable zip file\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "zip_name = f\"CurriTail_Results_{timestamp}.zip\"\n",
    "\n",
    "!zip -r {zip_name} outputs/ figures/ saved_models/ -q\n",
    "\n",
    "print(f\"üì¶ Created: {zip_name}\")\n",
    "print(f\"   Size: \", end=\"\")\n",
    "!du -h {zip_name}\n",
    "\n",
    "print(\"\\n‚¨áÔ∏è Downloading...\")\n",
    "from google.colab import files\n",
    "files.download(zip_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697bc336",
   "metadata": {},
   "source": [
    "## üß™ 8. Optional: Run Tests & Failure Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b91bfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run unit tests (if test_suite.py was uploaded)\n",
    "import os\n",
    "\n",
    "if os.path.exists('test_suite.py'):\n",
    "    print(\"üß™ Running unit tests...\\n\")\n",
    "    %run test_suite.py\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è test_suite.py not found. Skipping tests.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9896d0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run failure analysis (if failure_analysis.py was uploaded)\n",
    "if os.path.exists('failure_analysis.py'):\n",
    "    print(\"üîç Running failure analysis...\\n\")\n",
    "    %run failure_analysis.py\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è failure_analysis.py not found. Skipping analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c043a99",
   "metadata": {},
   "source": [
    "## üîß Troubleshooting\n",
    "\n",
    "### Common Issues:\n",
    "\n",
    "**1. \"RuntimeError: CUDA out of memory\"**\n",
    "- Reduce batch size: Set `batch_size = 128` in config\n",
    "- Restart runtime and clear GPU memory\n",
    "\n",
    "**2. \"Colab disconnected after X hours\"**\n",
    "- Use Colab Pro for longer sessions\n",
    "- Results are saved to Drive - you can resume\n",
    "- Keep browser tab active\n",
    "\n",
    "**3. \"Slow training speed\"**\n",
    "- Verify GPU is enabled (Cell 1)\n",
    "- Check batch size (larger = faster on GPU)\n",
    "- Use 'quick' mode first\n",
    "\n",
    "**4. \"ModuleNotFoundError\"**\n",
    "- Re-run installation cell\n",
    "- Ensure all .py files uploaded\n",
    "\n",
    "### Performance Tips:\n",
    "- **T4 GPU** (free): ~3-4 hours for quick mode\n",
    "- **A100 GPU** (Pro+): ~1-2 hours for quick mode  \n",
    "- **V100 GPU** (Pro): ~2-3 hours for quick mode\n",
    "\n",
    "### Support:\n",
    "- Check logs in Drive: `{project_dir}/outputs/metadata_*.json`\n",
    "- Review error messages carefully\n",
    "- Ensure GPU is properly allocated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0686a19",
   "metadata": {},
   "source": [
    "## üßπ 9. Cleanup (Optional)\n",
    "\n",
    "Free up Colab storage after downloading results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c787c358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove local files (results are in Google Drive)\n",
    "!rm -rf outputs/ figures/ saved_models/ data_cache/ *.zip\n",
    "print(\"‚úÖ Cleanup complete. Results remain in Google Drive.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d517a09",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Citation\n",
    "\n",
    "If you use this code in your research, please cite:\n",
    "\n",
    "```bibtex\n",
    "@article{curritailgan2024,\n",
    "  title={CurriTail-GAN: Curriculum Learning for Tail Generation in Financial Returns},\n",
    "  author={Your Name},\n",
    "  journal={Your Journal},\n",
    "  year={2024}\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**üéì Publication-Ready Experimental Suite**  \n",
    "**‚ö° Optimized for Google Colab GPU**  \n",
    "**üìä Complete Statistical Analysis Pipeline**\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
